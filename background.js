"use strict";

// ─────────────────────────────────────────────────────────────────────────────
// FODDER SYSTEM — Background Service Worker v10.0
// Supadata API → Slop Density Engine → DeepSeek LLM Verdict
// ─────────────────────────────────────────────────────────────────────────────

const MODEL_ID = "deepseek/deepseek-chat";

// ─── RYD (Return YouTube Dislike) ───────────────────────────────────────────
const RYD_CACHE = new Map();
const RYD_TTL   = 60 * 60 * 1000;

async function fetchRYD(videoId) {
  const c = RYD_CACHE.get(videoId);
  if (c && Date.now() - c.ts < RYD_TTL) return c.data;
  try {
    const r    = await fetch(`https://returnyoutubedislikeapi.com/Votes?videoId=${videoId}`);
    const data = await r.json();
    RYD_CACHE.set(videoId, { data, ts: Date.now() });
    return data;
  } catch (e) { return { error: e.message }; }
}

// ─────────────────────────────────────────────────────────────────────────────
// TRANSCRIPT — Supadata API
// Single source of truth. ~$0.001/request.
// Endpoint: GET https://api.supadata.ai/v1/youtube/transcript
// ─────────────────────────────────────────────────────────────────────────────

async function fetchTranscriptSupadata(videoId, apiKey) {
  if (!apiKey) {
    return {
      text:            "",
      isAutoGenerated: false,
      wordCount:       0,
      error:           "No Supadata API key configured — add one in the Fodder popup",
      source:          "none",
    };
  }

  const url = `https://api.supadata.ai/v1/youtube/transcript?videoId=${videoId}&text=true`;
  const res = await fetch(url, {
    headers: { "x-api-key": apiKey },
  });

  if (!res.ok) {
    const err = await res.json().catch(() => ({}));
    throw new Error(err?.message || `Supadata HTTP ${res.status}`);
  }

  const data = await res.json();

  // Normalize: Supadata returns { content: [...segments] } or { content: "text" }
  let text = "";
  if (data.content && Array.isArray(data.content)) {
    text = data.content.map(seg => seg.text || "").join(" ");
  } else if (typeof data.content === "string") {
    text = data.content;
  } else if (typeof data.text === "string") {
    text = data.text;
  }

  text = text.replace(/\n/g, " ").replace(/\s{2,}/g, " ").trim();

  if (!text) {
    return {
      text:            "",
      isAutoGenerated: false,
      wordCount:       0,
      error:           "Supadata returned empty transcript — video may have no captions",
      source:          "supadata-api",
    };
  }

  return {
    text,
    isAutoGenerated: false,
    wordCount:       text.split(/\s+/).length,
    error:           null,
    source:          "supadata-api",
  };
}

// ─────────────────────────────────────────────────────────────────────────────
// TRANSCRIPT FETCHER — cached wrapper around Supadata
// ─────────────────────────────────────────────────────────────────────────────

const TRANSCRIPT_CACHE = new Map();
const TRANSCRIPT_TTL   = 30 * 60 * 1000;

async function fetchTranscript(videoId, supadataKey) {
  const cached = TRANSCRIPT_CACHE.get(videoId);
  if (cached && Date.now() - cached.ts < TRANSCRIPT_TTL) return cached.data;

  let result;
  try {
    result = await fetchTranscriptSupadata(videoId, supadataKey);
  } catch (e) {
    console.warn(`[Fodder] Supadata failed for ${videoId}:`, e.message);
    result = {
      text:            "",
      isAutoGenerated: false,
      wordCount:       0,
      error:           `Supadata error: ${e.message}`,
      source:          "none",
    };
  }

  TRANSCRIPT_CACHE.set(videoId, { data: result, ts: Date.now() });
  return result;
}

// ─── SLOP DENSITY ENGINE v2 ─────────────────────────────────────────────────
// Pure deterministic scoring. No API calls. Runs locally on transcript text.
// ─────────────────────────────────────────────────────────────────────────────

const AI_PHRASES = new Set([
  "stands as a","serves as a","marks a pivotal","represents a shift","represents a turning point",
  "reflects broader","setting the stage for","indelible mark","deeply rooted",
  "underscores its importance","highlights its significance","symbolizing its",
  "contributing to the broader","shaping the course","lasting legacy","enduring legacy",
  "showcasing its","fostering a sense","cultivating a","encompassing a","reflecting its",
  "ensuring that we","highlighting the importance","underscoring the need","demonstrating its",
  "nestled in","nestled within","in the heart of","breathtaking views","must-visit destination",
  "stunning backdrop","boasts a rich","vibrant community","rich cultural heritage","rich history of",
  "nestled among","stands as","acts as a bridge","serves as an example","functions as a",
  "not only but also","not only does","not merely a","it's not just","it is not merely",
  "not just about","it goes beyond",
  "delve into","delve deeper","let's delve","we'll delve","deep dive into","deep-dive into",
  "take a deep dive","tapestry of","rich tapestry","intricate tapestry","complex tapestry",
  "testament to","enduring testament","stands as testament","paradigm shift","shift in paradigm",
  "game changer","game-changer","game changing","evolving landscape","ever-evolving landscape",
  "rapidly evolving landscape","in the realm of","in the landscape of","in the ecosystem of",
  "navigating the landscape","navigate the complexities","navigating this landscape",
  "the interplay between","the interplay of","the intricacies of","intricate dance","intricate web",
  "intricate balance","intricate relationship","multifaceted approach","holistic approach",
  "holistic understanding","comprehensive guide","comprehensive overview","comprehensive look",
  "actionable insights","actionable steps","actionable strategies","actionable tips",
  "leveraging the power","harnessing the power","harnessing the potential","multifaceted nature",
  "complex interplay","delicate balance","nuanced understanding","profound impact",
  "transformative impact","groundbreaking research","revolutionary approach","pioneering work",
  "cutting-edge research","state-of-the-art","industry-leading",
  "in today's video","in this video we","today we'll be","today we're going to",
  "welcome back to my","welcome back everyone","let's dive in","let's dive deep",
  "let's get started","without further ado","buckle up",
  "make sure to like","make sure to subscribe","hit that notification bell",
  "smash that like button","don't forget to subscribe","see you in the next one",
  "see you in the next video","that's all for today","that's going to wrap",
  "thanks for watching","drop a comment below","let me know in the comments",
  "if you found this helpful","if you enjoyed this video",
  "i hope this helps","hope this helps","let me know if you",
  "great question","excellent question","wonderful question",
  "excellent point","great point","that's a great","feel free to","don't hesitate to",
  "it's important to note that","it is important to note","it's worth noting that",
  "it is worth noting","it goes without saying","needless to say",
  "as of my last update","as of my knowledge","based on available information",
  "up to my knowledge cutoff","you're absolutely right","that's absolutely right",
  "exciting times ahead","exciting times","bright future","promising future","promising outlook",
  "at the end of the day","the bottom line is","continued success","continued growth",
  "the future is bright","looks promising","in the grand scheme","all things considered",
  "moving forward","going forward",
  "experts argue","experts suggest","experts believe","experts say","observers have noted",
  "industry reports suggest","many experts","studies have shown","research suggests",
  "research shows","according to experts","some researchers argue",
  "despite these challenges","despite its challenges","despite the challenges",
  "future outlook","challenges and opportunities","challenges and benefits",
  "despite this","despite these",
]);

const AI_VOCAB = new Set([
  "delve","nuanced","nuance","leverage","robust","streamline","actionable","paradigm","synergy",
  "ecosystem","holistic","seamless","empower","navigate","landscape","pivotal","paramount",
  "foster","realm","profound","intricate","multifaceted","groundbreaking","transformative",
  "innovative","comprehensive","captivating","fascinating","intriguing","remarkable","exceptional",
  "extraordinary","illuminate","elucidate","demystify","tapestry","testament","underscore",
  "garner","interplay","crucial","vibrant","showcase","align","enhance","enduring","valuable",
  "vital","significant","substantial","essential","fundamental","imperative","meticulous",
  "insightful","impactful","dynamic","compelling","cutting-edge","revolutionary","disruptive",
  "pioneering","fostering","highlighting","showcasing","underscoring","emphasizing","encompassing",
  "cultivating","illuminating","demonstrating","illustrating","unpack","untangle","explore",
  "journey","forward","vision","mission","unlock","catalyze","amplify","accelerate","reshape",
  "redefine","reimagine","reinvent","rethink",
]);

const AI_WEAK = new Set([
  "additionally","furthermore","moreover","nevertheless","nonetheless","in summary","in conclusion",
  "to summarize","to conclude","firstly","secondly","thirdly","fourthly","lastly","finally",
  "ultimately","overall","essentially","undeniably","undoubtedly","certainly","interesting",
  "unique","important","critical","vital",
]);

const HUMAN_STRONG = new Set(["uh","um","ugh","hmm","hm","uhh","umm","err","erm"]);
const HUMAN_MEDIUM = new Set([
  "like","you know","i mean","kinda","sorta","basically","honestly","right",
  "you know what i mean","does that make sense","i don't know","not sure","wait","hold on",
  "i think","i guess","kind of","sort of","i was like","to be honest","if that makes sense",
  "i might be wrong","could be wrong","don't quote me","actually wait","no wait","no that's",
  "actually no","i take that back","well","okay so","so like","anyway",
]);
const HUMAN_WEAK = new Set([
  "gonna","wanna","gotta","dude","man","bro","brah","mate","yeah","yep","yup","nah","nope",
  "whatever","literally","totally","seriously","legit","wild","crazy","insane","nuts","weird",
  "stuff","thing","things","kinda",
]);

const STRUCT = {
  sycophantic:   /\b(great|excellent|wonderful|amazing|fantastic|brilliant)\s+(question|point|observation|insight|example|idea)\b/gi,
  ruleOfThree:   /\b[\w]+(?:\s[\w]+){0,3},\s[\w]+(?:\s[\w]+){0,3},?\s+and\s+[\w]+(?:\s[\w]+){0,3}\b/g,
  transitionSeq: /\b(first(?:ly)?|to begin|to start)\b.{0,300}\b(second(?:ly)?|next|then)\b.{0,300}\b(third(?:ly)?|finally|lastly)\b/si,
  positiveEnd:   /\b(exciting\s+times|bright\s+future|promising\s+(?:future|outlook)|continued\s+(?:success|growth|excellence)|looking\s+forward\s+to)\b/gi,
  ctaCluster:    /\b(like\s+and\s+subscribe|hit\s+(?:that\s+)?(?:notification|subscribe)|bell\s+icon|smash\s+(?:that\s+)?like|comment\s+below|subscribe\s+button)\b/gi,
  negParallel:   /\bnot\s+only\b.{0,150}\bbut\b/gi,
  numTransition: /\b(firstly|secondly|thirdly|fourthly|lastly)\b/gi,
  fakeRange:     /\bfrom\s+[\w\s]{3,30}\s+to\s+[\w\s]{3,30}(?:,|\s+and|\s+as\s+well)/gi,
  em_dash_heavy: /—.{0,60}—/g,
};

function computeSlopDensity(text) {
  if (!text || text.length < 50)
    return { slopScore: 0, humanScore: 0, verdict: "UNKNOWN", confidence: "low", topSignals: [] };

  const lower = text.toLowerCase();
  const words = lower.split(/\s+/);
  const total = words.length;
  let slop = 0, human = 0;
  const signals = [];

  // ── Word-level scoring ──
  for (const raw of words) {
    const w = raw.replace(/[^a-z']/g, "");
    if (!w) continue;
    if (AI_VOCAB.has(w))     slop  += 2;
    if (AI_WEAK.has(w))      slop  += 1;
    if (HUMAN_STRONG.has(w)) human += 3;
    if (HUMAN_MEDIUM.has(w)) human += 2;
    if (HUMAN_WEAK.has(w))   human += 1;
  }

  // ── Phrase-level scoring ──
  for (const phrase of AI_PHRASES) {
    let idx = 0, count = 0;
    while ((idx = lower.indexOf(phrase, idx)) !== -1) { slop += 3; count++; idx += phrase.length; }
    if (count > 0) signals.push({ label: `"${phrase}"`, count, pts: count * 3 });
  }

  // ── Structural pattern scoring ──
  let structural = 0;
  const syco = (lower.match(STRUCT.sycophantic) || []).length;
  if (syco)    { structural += syco * 5;  signals.push({ label: "sycophantic opener",           count: syco,  pts: syco * 5 });  }
  const rot = (lower.match(STRUCT.ruleOfThree) || []).length;
  if (rot >= 3){ structural += 8;         signals.push({ label: "rule-of-three overuse",         count: rot,   pts: 8 });         }
  STRUCT.transitionSeq.lastIndex = 0;
  if (STRUCT.transitionSeq.test(lower)) { structural += 7; signals.push({ label: "scripted transition chain", count: 1, pts: 7 }); }
  const posEnd = (lower.match(STRUCT.positiveEnd) || []).length;
  if (posEnd)  { structural += posEnd*4;  signals.push({ label: "generic positive conclusion",   count: posEnd, pts: posEnd*4 }); }
  const cta = (lower.match(STRUCT.ctaCluster) || []).length;
  if (cta)     { structural += cta*3;     signals.push({ label: "YouTube CTA cluster",           count: cta,  pts: cta*3 });     }
  const negP = (lower.match(STRUCT.negParallel) || []).length;
  if (negP)    { structural += negP*4;    signals.push({ label: "negative parallelism",          count: negP, pts: negP*4 });    }
  const numT = (lower.match(STRUCT.numTransition) || []).length;
  if (numT>=2) { structural += numT*2;    signals.push({ label: "firstly/secondly chain",        count: numT, pts: numT*2 });    }
  const fr = (lower.match(STRUCT.fakeRange) || []).length;
  if (fr>=2)   { structural += fr*2;      signals.push({ label: "false range construction",      count: fr,   pts: fr*2 });      }
  const em = (lower.match(STRUCT.em_dash_heavy) || []).length;
  if (em>=3)   { structural += em*2; }

  slop += structural;

  // ── Normalize to 0–100 scale ──
  const per1k = pts => (pts / total) * 1000;
  const slopScore  = Math.round(Math.min(per1k(slop)  * 0.48, 100) * 10) / 10;
  const humanScore = Math.round(Math.min(per1k(human) * 1.40, 100) * 10) / 10;
  const confidence = total > 1200 ? "high" : total > 350 ? "medium" : "low";

  // ── Verdict classification ──
  let verdict;
  if      (slopScore >= 55 && humanScore < 15)  verdict = "SYNTHETIC";
  else if (slopScore >= 30 && humanScore < 22)  verdict = "ASSISTED";
  else if (slopScore < 18  && humanScore < 18)  verdict = "SCRIPTED";
  else if (slopScore < 22  && humanScore >= 28) verdict = "ORGANIC";
  else if (humanScore >= 40)                    verdict = "ORGANIC";
  else                                          verdict = "HYBRID";

  signals.sort((a, b) => b.pts - a.pts);
  return { slopScore, humanScore, verdict, confidence, topSignals: signals.slice(0, 6) };
}

// ─── COMMENT PREPROCESSING ───────────────────────────────────────────────────
function stripHtml(str) {
  return str
    .replace(/<br\s*\/?>/gi, " ").replace(/<[^>]+>/g, "")
    .replace(/&amp;/g,"&").replace(/&lt;/g,"<").replace(/&gt;/g,">")
    .replace(/&quot;/g,'"').replace(/&#39;/g,"'").replace(/&nbsp;/g," ")
    .trim();
}
function normalizeComment(text) {
  return text.toLowerCase()
    .replace(/[\p{Emoji_Presentation}\p{Extended_Pictographic}]/gu, "")
    .replace(/[^\w\s]/g,"").replace(/\s{2,}/g," ").trim();
}
function isJunk(text) {
  const stripped = text.replace(/[\s\p{Emoji_Presentation}\p{Extended_Pictographic}]/gu,"");
  return stripped.length < 8 || text.split(/\s+/).length < 4;
}

function preprocessComments(rawBaseline, rawSignal) {
  const sanitize = arr => arr.map(stripHtml).filter(Boolean);
  const baseClean   = sanitize(rawBaseline);
  const signalClean = sanitize(rawSignal);
  const all         = [...baseClean, ...signalClean];

  const fps = new Map();
  for (const c of all) {
    const fp = normalizeComment(c).slice(0, 55);
    if (!fp) continue;
    if (!fps.has(fp)) fps.set(fp, []);
    fps.get(fp).push(c);
  }

  const inorganicClusters = [];
  const flagged           = new Set();
  for (const [, group] of fps) {
    if (group.length >= 3) {
      inorganicClusters.push({ sample: group[0].slice(0,80), count: group.length, severity: group.length >= 8 ? "high" : group.length >= 5 ? "medium" : "low" });
      group.forEach(c => flagged.add(c));
    }
  }

  const clean = arr => arr.filter(c => !isJunk(c) && !flagged.has(c));
  const capComments = (arr, maxChars) => {
    const out = []; let budget = maxChars;
    for (const c of arr) { const s = c.slice(0,130); if (budget - s.length < 0) break; out.push(s); budget -= s.length; }
    return out;
  };

  const botsDetected = inorganicClusters.reduce((s,c) => s+c.count, 0);
  const botRatio     = all.length > 0 ? botsDetected / all.length : 0;

  return {
    baseline:          capComments(clean(baseClean),  2400),
    liveSignal:        capComments(clean(signalClean), 4000),
    inorganicClusters, botsDetected,
    botRatio:          Math.round(botRatio * 100),
    astroturfed:       botRatio > 0.30,
    hasData:           baseClean.length > 0 || signalClean.length > 0,
    insufficient:      clean(baseClean).length < 3 && clean(signalClean).length < 3,
  };
}

// ─── COMMENTS FETCH ──────────────────────────────────────────────────────────
const COMMENTS_CACHE = new Map();
const COMMENTS_TTL   = 15 * 60 * 1000;

async function fetchComments(videoId, apiKey) {
  if (!apiKey) return null;
  const cached = COMMENTS_CACHE.get(videoId);
  if (cached && Date.now() - cached.ts < COMMENTS_TTL) return cached.data;
  try {
    const BASE = "https://www.googleapis.com/youtube/v3/commentThreads";
    const [relRes, newRes] = await Promise.all([
      fetch(`${BASE}?part=snippet&videoId=${videoId}&maxResults=25&order=relevance&key=${apiKey}`),
      fetch(`${BASE}?part=snippet&videoId=${videoId}&maxResults=50&order=time&key=${apiKey}`),
    ]);
    if (!relRes.ok || !newRes.ok) {
      return { error: "HTTP Error", hasData: false, insufficient: true };
    }
    const [rel, newest] = await Promise.all([relRes.json(), newRes.json()]);
    const pluck = d => (d.items || []).map(i => i.snippet.topLevelComment.snippet.textDisplay);
    const result = { ...preprocessComments(pluck(rel), pluck(newest)), error: null };
    COMMENTS_CACHE.set(videoId, { data: result, ts: Date.now() });
    return result;
  } catch (e) {
    return { error: e.message, hasData: false, insufficient: true };
  }
}

// ─── LLM ANALYSIS ────────────────────────────────────────────────────────────
async function analyzeWithOpenRouter(videoId, transcript, slopData, comments, apiKey) {
  if (!apiKey) return null;
  if (!transcript?.text && !comments?.hasData) return null;

  const hasComments  = comments?.hasData && !comments?.insufficient;
  const topSignalStr = slopData?.topSignals?.map(s => `${s.label} ×${s.count}`).join(", ") || "none";

  let transcriptSection = "";
  if (transcript?.text) {
    transcriptSection =
      `TRANSCRIPT EXCERPT:\n${transcript.text.slice(0, 2000)}\n\n` +
      `SLOP SCORE: ${slopData?.slopScore ?? "N/A"}% | HUMAN SCORE: ${slopData?.humanScore ?? "N/A"}%\n` +
      `SLOP VERDICT: ${slopData?.verdict ?? "N/A"}\n` +
      `TOP AI SIGNALS: ${topSignalStr}\n`;
  }

  let communitySection = "";
  let driftInstruction = "";

  if (hasComments) {
    const botWarn = comments.astroturfed
      ? `⚠️ INORGANIC ALERT: ${comments.botRatio}% bot/clone ratio. ${comments.inorganicClusters.length} clusters.\n`
      : comments.botsDetected > 0
        ? `NOTE: ${comments.botsDetected} inorganic clones removed pre-analysis.\n`
        : "";

    communitySection =
      `\n${botWarn}` +
      `TOP 25 COMMENTS — established consensus (most upvoted, settled opinion):\n` +
      `${comments.baseline.join("\n").slice(0, 2200) || "(none)"}\n\n` +
      `RECENT 50 COMMENTS — live signal (newest, current reception):\n` +
      `${comments.liveSignal.join("\n").slice(0, 3500) || "(none)"}\n`;

    driftInstruction =
      `\n3. drift_score: integer -100 to +100. Compare ONLY the sentiment of "Recent 50" vs "Top 25". ` +
      `Ask: "Has the live reception CHANGED relative to the settled consensus?" ` +
      `Score near 0 (STABLE) if similar. Score negative only for measurable DETERIORATION. ` +
      `Score positive only for measurable IMPROVEMENT.\n` +
      `4. drift_state: "VIRAL"(>25), "BUILDING"(10-25), "STABLE"(-10 to 10), "SOURING"(-30 to -10), "SPOILING"(<-30)` +
      (comments.astroturfed ? `, or "ASTROTURFED" if bot ratio poisons the signal.` : ".") +
      `\n5. community_insight: 1-2 sentences, deadpan Fodder voice, about what has CHANGED between the two groups.`;
  }

  const schema = hasComments
    ? `{"transcript_verdict":"...","authenticity_signal":"high|medium|low","drift_score":<int>,"drift_state":"...","community_insight":"..."}`
    : `{"transcript_verdict":"...","authenticity_signal":"high|medium|low"}`;

  const prompt =
    `You are a clinical content analyst for the Fodder System.\n` +
    `Be deadpan, sardonic, precise. No filler phrases.\n\n` +
    transcriptSection + communitySection +
    `\nTASKS:\n` +
    `1. transcript_verdict: 2 sentences analyzing whether this transcript is genuinely human-made or AI-generated.\n` +
    `2. authenticity_signal: "high" (genuine/human), "medium" (ambiguous), "low" (AI/filler).\n` +
    driftInstruction +
    `\n\nRespond ONLY with valid JSON, no markdown:\n${schema}`;

  try {
    const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type":  "application/json",
        "Authorization": `Bearer ${apiKey}`,
        "HTTP-Referer":  "https://github.com/fodder-extension",
        "X-Title":       "Fodder System",
      },
      body: JSON.stringify({
        model:       MODEL_ID,
        max_tokens:  350,
        temperature: 0.25,
        messages:    [{ role: "user", content: prompt }],
      }),
    });

    if (!res.ok) throw new Error(`HTTP ${res.status}`);

    const data   = await res.json();
    const raw    = data.choices?.[0]?.message?.content || "";
    const clean  = raw.replace(/```(?:json)?\n?|\n?```/g, "").trim();
    const parsed = JSON.parse(clean);

    if (typeof parsed.drift_score === "number") {
      parsed.drift_score = Math.max(-100, Math.min(100, Math.round(parsed.drift_score)));
    }
    if (parsed.drift_state && typeof parsed.drift_state === "string") {
      parsed.drift_state = parsed.drift_state.toUpperCase();
    }
    if (parsed.authenticity_signal) {
      parsed.authenticity_signal = parsed.authenticity_signal.toLowerCase();
    }

    if (hasComments) {
      parsed.botsDetected      = comments.botsDetected;
      parsed.botRatio          = comments.botRatio;
      parsed.astroturfed       = comments.astroturfed;
      parsed.inorganicClusters = comments.inorganicClusters;
    }
    return parsed;
  } catch (e) {
    return { transcript_verdict: "Model unavailable.", authenticity_signal: "medium", error: e.message };
  }
}

// ─── FULL ANALYSIS PIPELINE ──────────────────────────────────────────────────
const ANALYSIS_CACHE = new Map();
const ANALYSIS_TTL   = 30 * 60 * 1000;

async function runFullAnalysis(videoId) {
  const cached = ANALYSIS_CACHE.get(videoId);
  if (cached && Date.now() - cached.ts < ANALYSIS_TTL) return cached.data;

  try {
    const { openrouterApiKey = null, ytApiKey = null, supadataApiKey = null } =
      await chrome.storage.sync.get(["openrouterApiKey", "ytApiKey", "supadataApiKey"]);

    // Transcript (Supadata) and comments (YouTube Data API) run in parallel
    const [transcript, comments] = await Promise.all([
      fetchTranscript(videoId, supadataApiKey),
      fetchComments(videoId, ytApiKey),
    ]);

    console.log(`[Fodder] Transcript for ${videoId}: source=${transcript.source}, words=${transcript.wordCount}, error=${transcript.error}`);

    // Run slop density on whatever text we got
    const slopData = computeSlopDensity(transcript.text);

    // Send transcript + slop results to LLM for final verdict
    const llm = await analyzeWithOpenRouter(videoId, transcript, slopData, comments, openrouterApiKey);

    const result = { transcript, slopData, llm, comments };
    ANALYSIS_CACHE.set(videoId, { data: result, ts: Date.now() });
    return result;
  } catch (e) {
    console.error(`[Fodder] runFullAnalysis UNCAUGHT for ${videoId}:`, e);
    throw e;
  }
}

// ─── MESSAGE ROUTER ──────────────────────────────────────────────────────────
chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
  if (request.type === "FETCH_RYD") {
    fetchRYD(request.videoId).then(sendResponse).catch(e => {
      console.error("[Fodder] FETCH_RYD crashed:", e);
      sendResponse({ error: e.message });
    });
    return true;
  }

  if (request.type === "FETCH_ANALYSIS") {
    runFullAnalysis(request.videoId)
      .then(sendResponse)
      .catch(e => {
        console.error("[Fodder] FETCH_ANALYSIS crashed:", e);
        sendResponse({
          transcript: { text: "", error: e.message, source: "crash", wordCount: 0 },
          slopData:   { slopScore: 0, humanScore: 0, verdict: "UNKNOWN", confidence: "low", topSignals: [] },
          llm:        null,
          comments:   null,
        });
      });
    return true;
  }
});
